{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9fd3b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c9fd3b1",
    "outputId": "6dfb3c43-950c-4147-fa08-191925ae8bb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 6s 0us/step\n",
      "Epoch 1/5\n",
      "782/782 [==============================] - 30s 37ms/step - loss: 1.8562 - accuracy: 0.3275 - val_loss: 1.7094 - val_accuracy: 0.3913\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 28s 35ms/step - loss: 1.6735 - accuracy: 0.4003 - val_loss: 1.6319 - val_accuracy: 0.4121\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 27s 35ms/step - loss: 1.5868 - accuracy: 0.4306 - val_loss: 1.5438 - val_accuracy: 0.4501\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 1.5314 - accuracy: 0.4508 - val_loss: 1.5662 - val_accuracy: 0.4439\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 27s 35ms/step - loss: 1.4901 - accuracy: 0.4687 - val_loss: 1.5398 - val_accuracy: 0.4586\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.5398 - accuracy: 0.4586\n",
      "Epoch 1/5\n",
      "169/782 [=====>........................] - ETA: 19s - loss: 2.2128 - accuracy: 0.1831"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test) # Convert labels to one-hot encoding\n",
    "\n",
    "def create_model(hidden_units=None, activation=None):\n",
    "    model = models.Sequential([\n",
    "        layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        layers.Dense(hidden_units[0], activation=activation), # Hidden Layer 1\n",
    "        layers.Dense(hidden_units[1], activation=activation), # Hidden Layer 2\n",
    "        layers.Dense(hidden_units[2], activation=activation), # Hidden Layer 3\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "hidden_units_list = [(512, 256, 128), (256, 128, 64), (1024, 512, 256)]\n",
    "activation_list = ['relu', 'tanh', 'sigmoid']\n",
    "\n",
    "results_dict = {}\n",
    "counter = 1\n",
    "\n",
    "# Loop through combinations of hidden units and activations\n",
    "for hidden_units in hidden_units_list:\n",
    "    for activation in activation_list:\n",
    "\n",
    "        model = create_model(hidden_units=hidden_units, activation=activation)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
    "\n",
    "        _, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "        model_info = { # Create a dictionary for the current iteration\n",
    "            \"Hidden units\": hidden_units,\n",
    "            \"Activation\": activation,\n",
    "            \"Test accuracy\": round(test_acc * 100, 4)\n",
    "        }\n",
    "\n",
    "        results_dict[counter] = model_info # Add the current dictionary to the results dictionary\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "for key, value in results_dict.items():\n",
    "    print(f\"Run {key}:\")\n",
    "    for info_key, info_value in value.items():\n",
    "        print(f\"{info_key}: {info_value}\")\n",
    "    print(\"- -\" * 15) # Dict prints Separator\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "max_accuracy_run = max(results_dict, key=lambda k: results_dict[k][\"Test accuracy\"])\n",
    "max_accuracy_info = results_dict[max_accuracy_run]\n",
    "print(\"Run with the highest test accuracy:\")\n",
    "print(f\"Run {max_accuracy_run}:\")\n",
    "for info_key, info_value in max_accuracy_info.items():\n",
    "    print(f\"{info_key}: {info_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4722cc",
   "metadata": {
    "id": "0f4722cc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_images = 2\n",
    "sample_images = x_train[:num_images]\n",
    "predictions = model.predict(sample_images)\n",
    "\n",
    "def plot_probability_meter(predictions, image):\n",
    "    class_labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 2))\n",
    "\n",
    "    # Plot the image\n",
    "    axs[0].imshow(image)\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Plot the probability meter\n",
    "    axs[1].barh(class_labels, predictions[0], color='blue')\n",
    "    axs[1].set_xlim([0, 1])\n",
    "    # axs[1].set_xlabel('Probability')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for i in range(num_images):\n",
    "    plot_probability_meter(predictions[i:i+1], sample_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saWws6OgGjui",
   "metadata": {
    "id": "saWws6OgGjui"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
