{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOZb6Or54YbRTJuf+jVLEUy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T-gChU-X2FhN","executionInfo":{"status":"ok","timestamp":1700437788183,"user_tz":-330,"elapsed":2792,"user":{"displayName":"Jayasankar Shyam","userId":"02759093510154047576"}},"outputId":"0cc050ac-c0da-43c6-9965-dc18b0636892"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"QAGQmhmU1z3z","executionInfo":{"status":"ok","timestamp":1700437788183,"user_tz":-330,"elapsed":2,"user":{"displayName":"Jayasankar Shyam","userId":"02759093510154047576"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n","from tensorflow.keras.models import Model\n","\n","eng_hin ='/content/drive/MyDrive/DL LAB/Notebooks/English_Hindi_Clean_New.csv'\n","data=pd.read_csv(eng_hin, encoding='utf-8')"]},{"cell_type":"code","source":["# Get English and Hindi Vocabulary\n","all_eng_words = set()\n","for eng in data['English']:\n","    for word in eng.split():\n","        if word not in all_eng_words:\n","            all_eng_words.add(word)\n","\n","all_hin_words = set()\n","for hin in data['Hindi']:\n","    for word in hin.split():\n","        if word not in all_hin_words:\n","            all_hin_words.add(word)\n","\n","data['len_eng_sen'] = data['English'].apply(lambda x: len(x.split(\" \")))\n","data['len_hin_sen'] = data['Hindi'].apply(lambda x: len(x.split(\" \")))\n","\n","data = data[data['len_eng_sen'] <= 20]\n","data = data[data['len_hin_sen'] <= 20]\n","\n","max_len_src = max(data['len_hin_sen'])\n","max_len_tar = max(data['len_eng_sen'])\n","\n","inp_words = sorted(list(all_eng_words))\n","tar_words = sorted(list(all_hin_words))\n","num_enc_toks = len(all_eng_words)\n","num_dec_toks = len(all_hin_words) + 1  # for zero padding\n","\n","inp_tok_idx = dict((word, i + 1) for i, word in enumerate(inp_words))\n","tar_tok_idx = dict((word, i + 1) for i, word in enumerate(tar_words))\n","rev_inp_char_idx = dict((i, word) for word, i in inp_tok_idx.items())\n","rev_tar_char_idx = dict((i, word) for word, i in tar_tok_idx.items())"],"metadata":{"id":"d1ZxBqXK2Sa8","executionInfo":{"status":"ok","timestamp":1700437794635,"user_tz":-330,"elapsed":1544,"user":{"displayName":"Jayasankar Shyam","userId":"02759093510154047576"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Split the data into train and test\n","X, y = data['English'], data['Hindi']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Increase batch size\n","batch_size = 256\n","\n","# Generate batch data\n","def generate_batch(X=X_train, y=y_train, batch_size=batch_size):\n","    while True:\n","        for j in range(0, len(X), batch_size):\n","            enc_inp_data = np.zeros((batch_size, max_len_src), dtype='float32')\n","            dec_inp_data = np.zeros((batch_size, max_len_tar), dtype='float32')\n","            dec_tar_data = np.zeros((batch_size, max_len_tar, num_dec_toks), dtype='float32')\n","            for i, (inp_text, tar_text) in enumerate(zip(X[j:j + batch_size], y[j:j + batch_size])):\n","                for t, word in enumerate(inp_text.split()):\n","                    enc_inp_data[i, t] = inp_tok_idx[word]\n","                for t, word in enumerate(tar_text.split()):\n","                    if t < len(tar_text.split()) - 1:\n","                        dec_inp_data[i, t] = tar_tok_idx[word]\n","                    if t > 0:\n","                        dec_tar_data[i, t - 1, tar_tok_idx[word]] = 1.0\n","            yield [enc_inp_data, dec_inp_data], dec_tar_data\n"],"metadata":{"id":"QQ-MNPoX2YXf","executionInfo":{"status":"ok","timestamp":1700437794635,"user_tz":-330,"elapsed":3,"user":{"displayName":"Jayasankar Shyam","userId":"02759093510154047576"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["\n","# Encoder-Decoder Architecture\n","latent_dim = 250\n","\n","# Encoder\n","enc_inps = Input(shape=(None,))\n","enc_emb = Embedding(num_enc_toks, latent_dim, mask_zero=True)(enc_inps)\n","enc_lstm = LSTM(latent_dim, return_state=True)\n","enc_outputs, st_h, st_c = enc_lstm(enc_emb)\n","enc_states = [st_h, st_c]\n","\n","# Set up the decoder\n","dec_inps = Input(shape=(None,))\n","dec_emb_layer = Embedding(num_dec_toks, latent_dim, mask_zero=True)\n","dec_emb = dec_emb_layer(dec_inps)\n","dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","dec_outputs, _, _ = dec_lstm(dec_emb, initial_state=enc_states)\n","dec_dense = Dense(num_dec_toks, activation='softmax')\n","dec_outputs = dec_dense(dec_outputs)\n"],"metadata":{"id":"_bsRbma42bgu","executionInfo":{"status":"ok","timestamp":1700437802842,"user_tz":-330,"elapsed":7568,"user":{"displayName":"Jayasankar Shyam","userId":"02759093510154047576"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Define the model\n","model = Model([enc_inps, dec_inps], dec_outputs)\n","model.compile(optimizer='adam', loss='categorical_crossentropy')  # Use Adam optimizer for faster convergence"],"metadata":{"id":"4LRrtDcF2eLf","executionInfo":{"status":"ok","timestamp":1700437802842,"user_tz":-330,"elapsed":4,"user":{"displayName":"Jayasankar Shyam","userId":"02759093510154047576"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train_samples = len(X_train)\n","val_samples = len(X_test)\n","\n","# Train the model with a larger batch size\n","model.fit(x=generate_batch(X_train, y_train, batch_size=batch_size),\n","          steps_per_epoch=train_samples // batch_size,\n","          epochs=50,\n","          validation_data=generate_batch(X_test, y_test, batch_size=batch_size),\n","          validation_steps=val_samples // batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mMMY1lmt2hg4","outputId":"01ff64ac-49c5-4066-f0fb-33a80b242047","executionInfo":{"status":"ok","timestamp":1700439033533,"user_tz":-330,"elapsed":1230694,"user":{"displayName":"Jayasankar Shyam","userId":"02759093510154047576"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","48/48 [==============================] - 51s 733ms/step - loss: 7.5685 - val_loss: 6.5462\n","Epoch 2/50\n","48/48 [==============================] - 24s 468ms/step - loss: 6.3515 - val_loss: 6.4169\n","Epoch 3/50\n","48/48 [==============================] - 23s 487ms/step - loss: 6.1858 - val_loss: 6.2884\n","Epoch 4/50\n","48/48 [==============================] - 22s 466ms/step - loss: 6.0260 - val_loss: 6.2312\n","Epoch 5/50\n","48/48 [==============================] - 22s 472ms/step - loss: 5.9087 - val_loss: 6.1894\n","Epoch 6/50\n","48/48 [==============================] - 25s 532ms/step - loss: 5.7970 - val_loss: 6.1295\n","Epoch 7/50\n","48/48 [==============================] - 22s 460ms/step - loss: 5.6693 - val_loss: 6.0397\n","Epoch 8/50\n","48/48 [==============================] - 21s 438ms/step - loss: 5.5310 - val_loss: 5.9482\n","Epoch 9/50\n","48/48 [==============================] - 25s 520ms/step - loss: 5.3997 - val_loss: 5.8899\n","Epoch 10/50\n","48/48 [==============================] - 21s 439ms/step - loss: 5.2885 - val_loss: 5.8420\n","Epoch 11/50\n","48/48 [==============================] - 21s 444ms/step - loss: 5.1836 - val_loss: 5.8081\n","Epoch 12/50\n","48/48 [==============================] - 25s 514ms/step - loss: 5.0852 - val_loss: 5.7963\n","Epoch 13/50\n","48/48 [==============================] - 26s 555ms/step - loss: 4.9965 - val_loss: 5.7754\n","Epoch 14/50\n","48/48 [==============================] - 26s 542ms/step - loss: 4.9157 - val_loss: 5.7809\n","Epoch 15/50\n","48/48 [==============================] - 22s 467ms/step - loss: 4.8404 - val_loss: 5.7708\n","Epoch 16/50\n","48/48 [==============================] - 26s 555ms/step - loss: 4.7655 - val_loss: 5.7773\n","Epoch 17/50\n","48/48 [==============================] - 26s 538ms/step - loss: 4.6926 - val_loss: 5.7757\n","Epoch 18/50\n","48/48 [==============================] - 25s 524ms/step - loss: 4.6254 - val_loss: 5.7852\n","Epoch 19/50\n","48/48 [==============================] - 21s 445ms/step - loss: 4.5503 - val_loss: 5.7964\n","Epoch 20/50\n","48/48 [==============================] - 22s 472ms/step - loss: 4.4682 - val_loss: 5.7785\n","Epoch 21/50\n","48/48 [==============================] - 21s 449ms/step - loss: 4.3879 - val_loss: 5.7714\n","Epoch 22/50\n","48/48 [==============================] - 26s 546ms/step - loss: 4.3104 - val_loss: 5.8050\n","Epoch 23/50\n","48/48 [==============================] - 21s 444ms/step - loss: 4.2327 - val_loss: 5.7788\n","Epoch 24/50\n","48/48 [==============================] - 21s 452ms/step - loss: 4.1536 - val_loss: 5.7762\n","Epoch 25/50\n","48/48 [==============================] - 22s 473ms/step - loss: 4.0793 - val_loss: 5.8016\n","Epoch 26/50\n","48/48 [==============================] - 22s 454ms/step - loss: 4.0045 - val_loss: 5.7942\n","Epoch 27/50\n","48/48 [==============================] - 25s 518ms/step - loss: 3.9288 - val_loss: 5.7994\n","Epoch 28/50\n","48/48 [==============================] - 26s 539ms/step - loss: 3.8488 - val_loss: 5.8224\n","Epoch 29/50\n","48/48 [==============================] - 22s 468ms/step - loss: 3.7717 - val_loss: 5.8369\n","Epoch 30/50\n","48/48 [==============================] - 25s 524ms/step - loss: 3.7008 - val_loss: 5.8460\n","Epoch 31/50\n","48/48 [==============================] - 26s 542ms/step - loss: 3.6340 - val_loss: 5.8649\n","Epoch 32/50\n","48/48 [==============================] - 22s 457ms/step - loss: 3.5610 - val_loss: 5.8744\n","Epoch 33/50\n","48/48 [==============================] - 22s 457ms/step - loss: 3.4863 - val_loss: 5.8901\n","Epoch 34/50\n","48/48 [==============================] - 24s 514ms/step - loss: 3.4057 - val_loss: 5.9101\n","Epoch 35/50\n","48/48 [==============================] - 22s 471ms/step - loss: 3.3266 - val_loss: 5.9330\n","Epoch 36/50\n","48/48 [==============================] - 25s 530ms/step - loss: 3.2485 - val_loss: 5.9363\n","Epoch 37/50\n","48/48 [==============================] - 22s 465ms/step - loss: 3.1697 - val_loss: 5.9648\n","Epoch 38/50\n","48/48 [==============================] - 21s 450ms/step - loss: 3.0923 - val_loss: 6.0010\n","Epoch 39/50\n","48/48 [==============================] - 23s 480ms/step - loss: 3.0276 - val_loss: 6.0068\n","Epoch 40/50\n","48/48 [==============================] - 26s 541ms/step - loss: 2.9636 - val_loss: 6.0160\n","Epoch 41/50\n","48/48 [==============================] - 25s 526ms/step - loss: 2.9000 - val_loss: 6.0397\n","Epoch 42/50\n","48/48 [==============================] - 25s 535ms/step - loss: 2.8353 - val_loss: 6.0752\n","Epoch 43/50\n","48/48 [==============================] - 26s 542ms/step - loss: 2.7616 - val_loss: 6.0812\n","Epoch 44/50\n","48/48 [==============================] - 22s 469ms/step - loss: 2.6779 - val_loss: 6.0979\n","Epoch 45/50\n","48/48 [==============================] - 26s 546ms/step - loss: 2.6004 - val_loss: 6.1244\n","Epoch 46/50\n","48/48 [==============================] - 26s 541ms/step - loss: 2.5312 - val_loss: 6.1629\n","Epoch 47/50\n","48/48 [==============================] - 21s 447ms/step - loss: 2.4652 - val_loss: 6.1757\n","Epoch 48/50\n","48/48 [==============================] - 22s 466ms/step - loss: 2.4008 - val_loss: 6.2055\n","Epoch 49/50\n","48/48 [==============================] - 22s 458ms/step - loss: 2.3367 - val_loss: 6.2512\n","Epoch 50/50\n","48/48 [==============================] - 25s 523ms/step - loss: 2.2907 - val_loss: 6.2885\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7e4a7db5ff70>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# Encode the input sequence to get the \"thought vectors\"\n","enc_model = Model(enc_inps, enc_states)\n","\n","# Decoder setup\n","# Below tensors will hold the states of the previous time step\n","dec_st_inp_h = Input(shape=(latent_dim,))\n","dec_st_inp_c = Input(shape=(latent_dim,))\n","dec_states_inps = [dec_st_inp_h, dec_st_inp_c]\n","\n","dec_emb2= dec_emb_layer(dec_inps) # Get the embeddings of the decoder sequence\n","\n","# To predict the next word in the sequence, set the initial states to the states from the previous time step\n","dec_outputs2, st_h2, st_c2 = dec_lstm(dec_emb2, initial_state=dec_states_inps)\n","dec_states2 = [st_h2, st_c2]\n","dec_outputs2 = dec_dense(dec_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n","\n","# Final decoder model\n","dec_model = Model(\n","    [dec_inps] + dec_states_inps,\n","    [dec_outputs2] + dec_states2)"],"metadata":{"id":"IVVtjgHT2k9I","executionInfo":{"status":"ok","timestamp":1700439042705,"user_tz":-330,"elapsed":666,"user":{"displayName":"Jayasankar Shyam","userId":"02759093510154047576"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def translate(inp_seq):\n","    # Encode the input as state vectors.\n","    states_value = enc_model.predict(inp_seq)\n","    # Generate empty target sequence of length 1.\n","    tar_seq = np.zeros((1,1))\n","    # Populate the first character of target sequence with the start character.\n","    tar_seq[0, 0] = tar_tok_idx['START_']\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_cond = False\n","    dec_sen = ''\n","    while not stop_cond:\n","        output_toks, h, c = dec_model.predict([tar_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_tok_idx = np.argmax(output_toks[0, -1, :])\n","        sampled_char = rev_tar_char_idx[sampled_tok_idx]\n","        dec_sen += ' '+sampled_char\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if (sampled_char == '_END' or\n","           len(dec_sen) > 50):\n","            stop_cond = True\n","\n","        # Update the target sequence (of length 1).\n","        tar_seq = np.zeros((1,1))\n","        tar_seq[0, 0] = sampled_tok_idx\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return dec_sen\n","\n","train_gen = generate_batch(X_train, y_train, batch_size = 1)\n","k=0\n","(inp_seq, actual_output), _ = next(train_gen)\n","hin_sen = translate(inp_seq)\n","print(f'''Input English sentence: {X_train[k:k+1].values[0]}\\n\n","          Predicted Hindi Translation: {hin_sen[:-4]}\\n\n","          Actual Hindi Translation: {y_train[k:k+1].values[0][6:-4]}''')"],"metadata":{"id":"Bvw8A0yI2nBJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700439047566,"user_tz":-330,"elapsed":4864,"user":{"displayName":"Jayasankar Shyam","userId":"02759093510154047576"}},"outputId":"feaa32b4-121f-4014-d98c-f0996bdacd54"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 2s 2s/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Input English sentence: which is a pity but in india every other sport\n","\n","          Predicted Hindi Translation:  जिसपे हमें तरस आती है कि भारत में एक एकल \n","\n","          Actual Hindi Translation:  जिसपे हमें तरस आती है लेकिन भारत में हर खेल \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NcTpFSOf5UTc","executionInfo":{"status":"ok","timestamp":1700439047566,"user_tz":-330,"elapsed":4,"user":{"displayName":"Jayasankar Shyam","userId":"02759093510154047576"}}},"execution_count":11,"outputs":[]}]}